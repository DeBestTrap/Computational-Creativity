{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install fairscale\n",
    "%pip install fire\n",
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LLM_DATA = os.environ['LLM_DATA']\n",
    "\n",
    "LLAMA_RUNNER = os.environ['LLAMA_RUNNER']\n",
    "GPT_RUNNER = os.environ['GPT_RUNNER']\n",
    "\n",
    "\n",
    "'''\n",
    "LLAMA PIPELINE\n",
    "'''\n",
    "\n",
    "def llama(input):\n",
    "\n",
    "    with open(LLM_DATA, 'w') as file:\n",
    "        json.dump(input, file, indent=4)\n",
    "\n",
    "    arguments = ['torchrun', \n",
    "                '--nproc_per_node=1', \n",
    "                f'{LLAMA_RUNNER}', \n",
    "                '--max_seq_len=512', \n",
    "                '--max_batch_size=6']\n",
    "    result = subprocess.run(arguments, capture_output=True, text=True)\n",
    "\n",
    "    print(\"Errors:\", result.stderr)\n",
    "    print(\"Return Code:\", result.returncode)\n",
    "\n",
    "    return result.stdout\n",
    "\n",
    "def parse_llama_result(data:str, begin_key=None, end_key=None, inclusive_begin=True):\n",
    "    story = data[data.find('[@RESPONSEBEGIN]'):data.find('[@RESPONSEEND]')]\n",
    "\n",
    "    # trims to between begin key and end key(if they exist)\n",
    "    begin_index = 0\n",
    "    if begin_key is not None:\n",
    "        begin_index = story.find(begin_key)\n",
    "        if not inclusive_begin:\n",
    "            begin_index += len(begin_key)\n",
    "\n",
    "    end_index = len(story)\n",
    "    if end_key is not None:\n",
    "        end_index = story.find(end_key)\n",
    "\n",
    "    story = story[begin_index:end_index]\n",
    "\n",
    "    return story\n",
    "\n",
    "def parse_characters(data:str):\n",
    "    characters = []\n",
    "    last_begin = 0\n",
    "    while(True):\n",
    "        begin = data.find('<', last_begin)\n",
    "        print(f'begin: {begin}')\n",
    "        if begin == -1:\n",
    "            break\n",
    "        last_begin = begin + 3\n",
    "\n",
    "        end = data.find('>', begin)\n",
    "        characters.append(data[begin + 1:end])\n",
    "    print(f\"found characters: {characters}\")\n",
    "    return characters\n",
    "\n",
    "\n",
    "'''\n",
    "GPT PIPELINE\n",
    "'''\n",
    "\n",
    "def gpt(input):\n",
    "    with open(LLM_DATA, 'w') as file:\n",
    "        json.dump(input, file, indent=4)\n",
    "\n",
    "    arguments = [\"python3\", f\"{GPT_RUNNER}\"]\n",
    "\n",
    "    result = subprocess.run(arguments, capture_output=True, text=True)\n",
    "\n",
    "    print(\"Errors:\", result.stderr)\n",
    "    print(\"Return Code:\", result.returncode)\n",
    "\n",
    "    return result.stdout\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_pipeline(prompt):\n",
    "\n",
    "    # things needed:\n",
    "    #   characters list\n",
    "    #   series of captions\n",
    "    #   series of dialogue and the character that says it\n",
    "\n",
    "    # obtaining story:\n",
    "    data = [\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": f\"write a story about {prompt}, breaking apart each scene into its own paragraph and label it with [SCENE <number>]. End the past paragraph with [END]\"}\n",
    "        ],\n",
    "    ]\n",
    "    story = llama(data)\n",
    "    story_parsed = parse_llama_result(story, \"[SCENE\", \"[END]\")\n",
    "\n",
    "    # obtaining characters\n",
    "    data = [\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": f\"here is a story: {story_parsed}\\nGenerate a list of characters that may be in this story by providing their names between triangle brackets as such in the following format: <name>\"}\n",
    "        ],\n",
    "    ]\n",
    "    characters = llama(data)\n",
    "    characters = parse_characters(characters)\n",
    "\n",
    "    # generating captions\n",
    "    data = [\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": f\"here is a story: {story_parsed}\\nGenerate a caption for each scene, labelling each caption with [SCENE <number>]. End the last caption with [END]\"}\n",
    "        ],\n",
    "    ]\n",
    "    captions = llama(data)\n",
    "    captions_parsed = parse_llama_result(captions, \"[SCENE\", \"[END]\")\n",
    "\n",
    "    # generating dialogue\n",
    "    data = [\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": f\"here is a story: {story_parsed}\\nGenerate a set of dialogues ranging from 1 to 3 for each scene, labelling each dialogue with [SCENE <number>][CHARACTER <character name>]. Use characters from the following pool: {','.join(characters)}\"}\n",
    "        ],\n",
    "    ]\n",
    "    dialogue = llama(data)\n",
    "    dialogue_parsed = parse_llama_result(dialogue, \"[SCENE\", \"[END]\")\n",
    "\n",
    "    print(f\"story_parsed: \\n{story_parsed}\\nEND\")\n",
    "    print(f\"characters parsed: \\n{characters}\\nEND\")\n",
    "    print(f\"captions_parsed: \\n{captions_parsed}\\nEND\")\n",
    "    print(f\"dialogue_parsed: \\n{dialogue_parsed}\\nEND\")\n",
    "\n",
    "\n",
    "def gpt_pipeline(prompt):\n",
    "    example = \"\"\"\n",
    "{\n",
    "    \"characters\": [\n",
    "        {\"name\": \"Radke\"}\n",
    "    ],\n",
    "    \"script\": [ \n",
    "        {\"caption\": \"A sheep looking at cheese in a supermarket.\", \n",
    "        \"dialogue\": [\n",
    "            {\"character\": \"Radke\", \"text\": \"In the mist-enshrouded hills of an ancient land, there lies a mystery as old as time itself. Behold the enigmatic sheep, creatures shrouded in the lore and legend of yesteryears.\"}\n",
    "        ]\n",
    "        }\n",
    "    ]\n",
    "}\"\"\"\n",
    "\n",
    "    data = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a TV show writer.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"generate a story about {prompt} by filling in a json file, remember that captions should be physical descriptions of an image, and the script should contain around 20 captions. The following json example shows all the fields you should create and fill in: {example}\"}\n",
    "    ]\n",
    "    response = gpt(data)\n",
    "\n",
    "    print(f'response:\\n{response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: \n",
      "Return Code: 0\n",
      "response:\n",
      "{\n",
      "    \"characters\": [\n",
      "        {\"name\": \"James\"},\n",
      "        {\"name\": \"Emily\"},\n",
      "        {\"name\": \"Sheriff Hank\"}\n",
      "    ],\n",
      "    \"script\": [ \n",
      "        {\"caption\": \"A swarm of sparrows descends on a wheat field, pecking away at the golden crops.\", \n",
      "        \"dialogue\": [\n",
      "            {\"character\": \"James\", \"text\": \"Emily, look! Our crops are under attack!\"},\n",
      "            {\"character\": \"Emily\", \"text\": \"Those birds... they're eating everything! What are we going to do?\"}\n",
      "        ]\n",
      "        },\n",
      "        {\"caption\": \"Countless deer causally munching on the green lettuce in the village's vegetable field.\", \n",
      "        \"dialogue\": [\n",
      "            {\"character\": \"Sheriff Hank\", \"text\": \"This is the worst outbreak we've had in decades. And it's not just the birds... the deer... they're ravaging the vegetable fields.\"},\n",
      "            {\"character\": \"James\", \"text\": \"We need to do something soon or the entire village will starve.\"}\n",
      "        ]\n",
      "        },\n",
      "        {\"caption\": \"Night falls and wolves start prowling on the outskirts of the village.\", \n",
      "        \"dialogue\": [\n",
      "            {\"character\": \"Emily\", \"text\": \"The night isn't safe anymore. The wolves... they're coming closer and closer to the village.\"},\n",
      "            {\"character\": \"Sheriff Hank\", \"text\": \"We need to work together to protect our village. We can't let the animals overrun us.\"},\n",
      "            {\"character\": \"James\", \"text\": \"Agreed, let's layout plans to safeguard our village and crops.\"}\n",
      "        ]\n",
      "        },\n",
      "        {\"caption\": \"The once bountiful fields now lay barren after days of relentless animal onslaught.\", \n",
      "        \"dialogue\": [\n",
      "            {\"character\": \"Sheriff Hank\", \"text\": \"Look at this wasteland... It's heartbreaking.\"},\n",
      "            {\"character\": \"Emily\", \"text\": \"We won't give up. We'll fight back and reclaim what's ours.\"},\n",
      "            {\"character\": \"James\", \"text\": \"Yes, we will. This is our land. We won't let the animals destroy our village.\"}\n",
      "        ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = 'animals overrunning a village and destroying its crops'\n",
    "gpt_pipeline(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
