{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from CLIP import clip\n",
    "from torchvision.datasets import Food101\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Load the CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Load food101\n",
    "food101_dataset = Food101(root='./food101_data', split='train', download=True)\n",
    "\n",
    "# subset_size = 512\n",
    "subset_size = 256*2**3\n",
    "print(subset_size)\n",
    "print(len(food101_dataset))\n",
    "\n",
    "subset_indices = torch.randperm(len(food101_dataset))[:subset_size]\n",
    "subset_dataset = Subset(food101_dataset, subset_indices)\n",
    "\n",
    "\n",
    "def custom_collate(batch):\n",
    "    batch_images = torch.stack([transforms.ToTensor()(transforms.Resize((224, 224))(img)) for img, _ in batch])\n",
    "    batch_images = batch_images.to(device)\n",
    "\n",
    "    return batch_images\n",
    "\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# process images and texts for the entire dataset\n",
    "subset_features = []\n",
    "scaler = GradScaler()\n",
    "\n",
    "for batch_images in dataloader:\n",
    "  with autocast():\n",
    "    batch_features = model.encode_image(batch_images)\n",
    "    subset_features.append(batch_features)\n",
    "\n",
    "subset_features = torch.cat(subset_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_images(input, model, transform, subset_features, dataset, top_k=5):\n",
    "    # Process the text description\n",
    "    text = clip.tokenize([input]).to(device)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    # get similarity between text and subset images\n",
    "    similarity_scores = torch.nn.functional.cosine_similarity(text_features, subset_features)\n",
    "\n",
    "    # Get indices of top-k similar images\n",
    "    top_k_indices = torch.topk(similarity_scores, top_k).indices.cpu().numpy()\n",
    "\n",
    "    # Display the top-k images\n",
    "    plt.figure(figsize=(15, 3))\n",
    "\n",
    "    plt.subplots_adjust(top=0.8)\n",
    "    plt.suptitle(f\"Input: {input}\", fontsize=16)\n",
    "\n",
    "    for i, idx in enumerate(top_k_indices):\n",
    "        ax = plt.subplot(1, top_k, i + 1)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"Top {i + 1}\")\n",
    "        plt.imshow(np.asarray(dataset[idx][0]))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "retrieve_images(\"soup\", model, preprocess, subset_features, subset_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_images(\"cereal\", model, preprocess, subset_features, subset_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_images(\"the best food\", model, preprocess, subset_features, subset_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_images(\"the worst food\", model, preprocess, subset_features, subset_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
